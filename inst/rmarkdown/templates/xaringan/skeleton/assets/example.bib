
@article{adamsHelenLoyOther2020,
  title = {Helen {{A}}'{{Loy}} and Other Tales of Female Automata: A Gendered Reading of the Narratives of Hopes and Fears of Intelligent Machines and Artificial Intelligence},
  shorttitle = {Helen {{A}}'{{Loy}} and Other Tales of Female Automata},
  author = {Adams, Rachel},
  year = {2020},
  month = sep,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {3},
  pages = {569--579},
  issn = {1435-5655},
  doi = {10.1007/s00146-019-00918-7},
  abstract = {The imaginative context in which artificial intelligence (AI) is embedded remains a crucial touchstone from which to understand and critique both the histories and prospective futures of an AI-driven world. A recent article from Cave and Dihal (Nat Mach Intell 1:74\textendash 78, 2019) sets out a narrative schema of four hopes and four corresponding fears associated with intelligent machines and AI. This article seeks to respond to the work of Cave and Dihal by presenting a gendered reading of this schema of hopes and fears. I offer a brief genealogy of narratives which feature female automata, before turning to examine how gendered technology today\textemdash particularly AI assistants like Siri and Alexa\textemdash reproduces the historical narratives associated with intelligent machines in new ways. Through a gendered reading of the hopes and fears associated with AI, two key responses arise. First, that the affective reactions to intelligent machines cannot be readily separated where such machines are gendered female. And second, that the gendering of AI technologies today can be understood as an attempt to reconcile the opposing hopes and fears AI produces, and that this reconciliation is based on the association of such technologies with traditional notions of femininity. Critically, a gendered reading enables us to problematize the narratives associated with AI and expose the power asymmetries that lie within, and the technologies which arise out of, such narratives.},
  langid = {english}
}

@article{arogyaswamyBigTechSocietal2020,
  title = {Big Tech and Societal Sustainability: An Ethical Framework},
  shorttitle = {Big Tech and Societal Sustainability},
  author = {Arogyaswamy, Bernard},
  year = {2020},
  month = dec,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {4},
  pages = {829--840},
  issn = {1435-5655},
  doi = {10.1007/s00146-020-00956-6},
  abstract = {Sustainability is typically viewed as consisting of three forces, economic, social, and ecological, in tension with one another. In this paper, we address the dangers posed to societal sustainability. The concern being addressed is the very survival of societies where the rights of individuals, personal and collective freedoms, an independent judiciary and media, and democracy, despite its messiness, are highly valued. We argue that, as a result of various technological innovations, a range of dysfunctional impacts are threatening social and political stability. For instance, robotics and automation are replacing human labor and decision-making in a range of industries; search engines, monetized through advertising, have access to, and track, our interests and preferences; social media, in connecting us to one another often know more about us than we ourselves do, enabling them to profit in ways which may not coincide with our well-being; online retailers have not only acquired the ability to track and predict our buying choices, but also they can squeeze vendors based on their outsize bargaining power; and, in general, virtual technologies have changed both the way we think and our sense of self. With the rising deployment of the Internet of Things, and developments in machine learning and artificial intelligence, the threats to individual freedoms and rights, societal cohesion and harmony, employment and economic well-being, and trust in democracy are being ratcheted up. This paper lauds the benefits and addresses the harm wrought by the high tech giants in Information and Communication Technologies (ICTs). The search for rapidly growing revenues (and shareholder returns and stock prices) drives firms to accelerate product innovation without fully investigating the entire gamut of their impacts. As greater wealth accrues to the leaders of tech firms, inequalities within firms and societies are widening, creating social tensions and political ferment. We explore the ethical nature of the challenge employing a simple utilitarian calculus, complemented by approaches rooted in rights, justice, and the common good. Various options to address the challenges posed by ICTs are considered and evaluated. We argue that regulation may do little more than slow down the damage to society, particularly since societal values and political preferences vary internationally. Firms need to establish ethical standards, imbuing the upholders of these standards with sufficient authority, while creating a culture of morality. User involvement and activism, and shareholders' concerns for the sustainability of societies on whose continued prosperity they depend, are imperative to humanity's ability to decide the future direction of technology.},
  langid = {english}
}

@article{bergenToDoBeFoucault2020,
  title = {To-{{Do Is}} to {{Be}}: {{Foucault}}, {{Levinas}}, and {{Technologically Mediated Subjectivation}}},
  author = {Bergen, Jan Peter},
  year = {2020},
  journal = {Philosophy \& Technology},
  pages = {24},
  abstract = {The theory of technological mediation aims to take technological artifacts seriously, recognizing the constitutive role they play in how we experience the world, act in it, and how we are constituted as (moral) subjects. Its quest for a compatible ethics has led it to Foucault's ``care of the self,'' i.e., a transformation of the self by oneself through self-discipline. In this regard, technologies have been interpreted as power structures to which one can relate through Foucaultian ``technologies of the self'' or ascetic practices. However, this leaves unexplored how concrete technologies can actually support the process of self-care. This paper explores this possibility by examining one such technology: a gamified ToDo list app. Doing so, it first shows that despite the apparent straightforwardness of gamification, confrontation and shame play an important role in how the app motivates me to do better. Second, inspired by Ihde's schema of humantechnology relations, it presents different ways in which the app may confront me with myself. Subsequently, it accounts for the motivation and shame that this technologically mediated confrontation with myself invokes through a Levinasian account of ethical subjectivity. In so doing, it also shows how Levinas' phenomenology implies a responsibility for self-care and how nonhuman, technological others may still call me to responsibility. It concludes with a reflection on the role of gamification in technologically mediated subjectivation and some implications for design.},
  langid = {english},
  keywords = {printed}
}

@article{coeckelberghTechnoperformancesUsingMetaphors2020,
  title = {Technoperformances: Using Metaphors from the Performance Arts for a Postphenomenology and Posthermeneutics of Technology Use},
  shorttitle = {Technoperformances},
  author = {Coeckelbergh, Mark},
  year = {2020},
  month = sep,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {3},
  pages = {557--568},
  issn = {1435-5655},
  doi = {10.1007/s00146-019-00926-7},
  abstract = {Postphenomenology and posthermeneutics as initiated by Ihde have made important contributions to conceptualizing understanding human\textendash technology relations. However, their focus on individual perception, artifacts, and static embodiment has its limitations when it comes to understanding the embodied use of technology as (1) involving bodily movement, (2) social, and (3) taking place within, and configuring, a temporal horizon. To account for these dimensions of experience, action, and existence with technology, this paper proposes to use a conceptual framework based on performance metaphors. Drawing on metaphors from three performance arts\textemdash dance, theatre, and music\textemdash and giving examples from social media and other technologies, it is shown that we can helpfully describe technology use and experience as performance involving movement, sociality, and temporality. Moreover, it is argued that these metaphors can also be used to reformulate the idea that in such uses and experiences, now understood as ``technoperformances'', technology is not merely a tool but also takes on a stronger, often non-intended role: not so much as ``mediator'' but as choreographer, director, and conductor of what we experience and do. Performance metaphors thus allow us to recast the phenomenology and hermeneutics of technology use as moving, social, and temporal\textemdash indeed historical\textemdash affair in which technologies take on the role of organizer and structurer of our performances, and in which humans are not necessarily the ones who are fully in control of the meanings, experiences, and actions that emerge from our engagement with the world, with technology, and with each other. This promises to give us a more comprehensive view of what it means to live with technology and how our lives are increasingly organized by technology\textemdash especially by smart technologies. Finally, it is argued that this has normative implications for an ethics and politics of technology, now understood as an ethics and politics of technoperformances.},
  langid = {english}
}

@article{dacquistoConflictsEthicalLogical2020,
  title = {On Conflicts between Ethical and Logical Principles in Artificial Intelligence},
  author = {D'Acquisto, Giuseppe},
  year = {2020},
  journal = {AI \& SOCIETY},
  volume = {35},
  pages = {895--900},
  doi = {10.1007/s00146-019-00927-6},
  abstract = {Artificial intelligence is nowadays a reality. Setting rules on the potential outcomes of intelligent machines, so that no surprise can be expected by humans from the behavior of those machines, is becoming a priority for policy makers. In its recent Communication ``Artificial Intelligence for Europe'' (EU Commission 2018), for instance, the European Commission identifies the distinguishing trait of an intelligent machine in the presence of ``a certain degree of autonomy'' in decision making, in the light of the context. The crucial issue to be addressed is, therefore, whether it is possible to identify a set of rules for data use by intelligent machines so that the decision-making autonomy of machines can allow for humans' traditional informational self-determination (humans provide machines only with the data they decide to), as enshrined in many existing legal frameworks (including, for personal data protection, the EU's General Data Protection Regulation) (EU Parliament and Council 2016) and can actually turn out to be further beneficial to individuals. Governing the autonomy of machines can be a very ambitious goal for humans since machines are geared first to the principles of formal logic and then\textemdash possibly\textemdash to ethical or legal principles. This introduces an unprecedented degree of complexity in how a norm should be engineered, which requires, in turn, an in-depth reflection in order to prevent conflicts between the legal and ethical principles underlying humans' civil coexistence and the rules of formal logic upon which the functioning of machines is based (EU Parliament 2017).},
  langid = {english}
}

@article{eglashAutomationArtisanalEconomy2020,
  title = {Automation for the Artisanal Economy: Enhancing the Economic and Environmental Sustainability of Crafting Professions with Human\textendash Machine Collaboration},
  shorttitle = {Automation for the Artisanal Economy},
  author = {Eglash, Ron and Robert, Lionel and Bennett, Audrey and Robinson, Kwame Porter and Lachney, Michael and Babbitt, William},
  year = {2020},
  month = sep,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {3},
  pages = {595--609},
  issn = {1435-5655},
  doi = {10.1007/s00146-019-00915-w},
  abstract = {Artificial intelligence (AI) is poised to eliminate millions of jobs, from finance to truck driving. But artisanal products (e.g., handmade textiles) are valued precisely because of their human origins, and thus have some inherent ``immunity'' from AI job loss. At the same time, artisanal labor, combined with technology, could potentially help to democratize the economy, allowing independent, small-scale businesses to flourish. Could AI, robotics and related automation technologies enhance the economic viability and environmental sustainability of these beloved crafting professions, perhaps even expanding their niche to replace some job loss in other sectors? In this paper, we compare the problems created by the current mass production economy and potential solutions from an artisanal economy. In doing so, the paper details the possibilities of utilizing AI to support hybrid forms of human\textendash machine production at the microscale; localized and sustainable value chains at the mesoscale; and networks of these localized and sustainable producers at the macroscale. In short, a wide range of automation technologies are potentially available for facilitating and empowering an artisanal economy. Ultimately, it is our hope that this paper will facilitate a discussion on a future vision for more ``generative'' economic forms in which labor value, ecological value and social value can circulate without extraction or alienation.},
  langid = {english}
}

@article{goagosesCommunityProtocolsResearchers2020,
  title = {Community Protocols for Researchers: Using Sketches to Communicate Interaction Guidelines},
  shorttitle = {Community Protocols for Researchers},
  author = {Goagoses, Naska and {Winschiers-Theophilus}, Heike and Zaman, Tariq},
  year = {2020},
  month = sep,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {3},
  pages = {675--687},
  issn = {1435-5655},
  doi = {10.1007/s00146-019-00914-x},
  abstract = {Reviews of research and development collaborations with indigenous communities have exhibited numerous challenges related to researcher\textendash community interactions. Based on many accounts of indiscretions, indigenous communities have begun generating conduct guidelines for researchers. However, the effectiveness of their chosen communication methods, guaranteeing appropriate behavior of the researchers, has not been established. This research contributes to an ongoing debate around appropriate ethical conduct of researchers in situ. The aim of this study was to investigate the interpretation accuracy of interaction guidelines produced in the form of sketches by a Malaysian indigenous community. We provided eight interaction sketches to 57 students, in three continents, for interpretation and expression of their intended behavior. We found that most were unable to accurately interpret the sketches and describe intended behavioral responses. A major concern remains with the tendency to fall back on prior practices of ``good'' behavior, with minimal guidance on contextual practices. In an attempt to provide greater direction, we explored a speech bubble exercise with further 15 students. Our findings directly contribute to current efforts in formulating researcher\textendash community interaction practices that should form the basis of ethical research in situ.},
  langid = {english}
}

@article{zawieskaDisengagementEthicsRobotics2020,
  title = {Disengagement with Ethics in Robotics as a Tacit Form of Dehumanisation},
  author = {Zawieska, Karolina},
  year = {2020},
  month = dec,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {4},
  pages = {869--883},
  issn = {1435-5655},
  doi = {10.1007/s00146-020-01000-3},
  abstract = {Over the past two decades, ethical challenges related to robotics technologies have gained increasing interest among different research and non-academic communities, in particular through the field of roboethics. While the reasons to address roboethics are clear, why not to engage with ethics needs to be better understood. This paper focuses on a limited or lacking engagement with ethics that takes place within some parts of the robotics community and its implications for the conceptualisation of the human being. The underlying assumption is that the term `ethical' essentially means `human'. Thus, this paper discusses a working hypothesis according to which by avoiding to engage with roboethics, roboticists contribute to the tacit dehumanisation process emerging in and outside of robotics. An alternative approach includes `lived ethics' which involves not only incorporating formal ethical approaches into the roboticists' work but also `being' ethical and actually engaging with ethical reflection and practice.},
  langid = {english}
}


